[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "On this about page, you might want to add more information about yourself, the project, or course. Any helpful context could go here!\nMy name is Nick Hand, the instructor for the course. You can find more information about me on my personal website.\nThis site is an example site showing how to use Quarto for the final project for MUSA 550, during fall 2023.\nAdipisicing proident minim non non dolor quis. Pariatur in ipsum aliquip magna. Qui ad aliqua nulla excepteur dolor nostrud quis nisi. Occaecat proident eiusmod in cupidatat. Elit qui laboris sit aliquip proident dolore. Officia commodo commodo in eiusmod aliqua sint cupidatat consectetur aliqua sint reprehenderit.\nOccaecat incididunt esse et elit adipisicing sit est cupidatat consequat. Incididunt exercitation amet dolor non sit anim veniam veniam sint velit. Labore irure reprehenderit ut esse. Minim quis commodo nisi voluptate."
  },
  {
    "objectID": "analysis/4-folium.html",
    "href": "analysis/4-folium.html",
    "title": "Interactive Maps with Folium",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive maps produced using Folium."
  },
  {
    "objectID": "analysis/4-folium.html#finding-the-shortest-route",
    "href": "analysis/4-folium.html#finding-the-shortest-route",
    "title": "Interactive Maps with Folium",
    "section": "Finding the shortest route",
    "text": "Finding the shortest route\nThis example finds the shortest route between the Art Musuem and the Liberty Bell using osmnx.\n\nimport osmnx as ox\n\nFirst, identify the lat/lng coordinates for our places of interest. Use osmnx to download the geometries for the Libery Bell and Art Museum.\n\nphilly_tourism = ox.features_from_place(\"Philadelphia, PA\", tags={\"tourism\": True})\n\n\nart_museum = philly_tourism.query(\"name == 'Philadelphia Museum of Art'\").squeeze()\n\nart_museum.geometry\n\n\n\n\n\nliberty_bell = philly_tourism.query(\"name == 'Liberty Bell'\").squeeze()\n\nliberty_bell.geometry\n\n\n\n\nNow, extract the lat and lng coordinates\nFor the Art Museum geometry, we can use the .geometry.centroid attribute to calculate the centroid of the building footprint.\n\nliberty_bell_x = liberty_bell.geometry.x\nliberty_bell_y = liberty_bell.geometry.y\n\n\nart_museum_x = art_museum.geometry.centroid.x\nart_museum_y = art_museum.geometry.centroid.y\n\nNext, use osmnx to download the street graph around Center City.\n\nG_cc = ox.graph_from_address(\n    \"City Hall, Philadelphia, USA\", dist=1500, network_type=\"drive\"\n)\n\nNext, identify the nodes in the graph closest to our points of interest.\n\n# Get the origin node (Liberty Bell)\norig_node = ox.nearest_nodes(G_cc, liberty_bell_x, liberty_bell_y)\n\n# Get the destination node (Art Musuem)\ndest_node = ox.nearest_nodes(G_cc, art_museum_x, art_museum_y)\n\nFind the shortest path, based on the distance of the edges:\n\n# Get the shortest path --&gt; just a list of node IDs\nroute = ox.shortest_path(G_cc, orig_node, dest_node, weight=\"length\")\n\nHow about an interactive version?\nosmnx has a helper function ox.utils_graph.route_to_gdf() to convert a route to a GeoDataFrame of edges.\n\nox.utils_graph.route_to_gdf(G_cc, route, weight=\"length\").explore(\n    tiles=\"cartodb positron\",\n    color=\"red\",\n)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/4-folium.html#examining-trash-related-311-requests",
    "href": "analysis/4-folium.html#examining-trash-related-311-requests",
    "title": "Interactive Maps with Folium",
    "section": "Examining Trash-Related 311 Requests",
    "text": "Examining Trash-Related 311 Requests\nFirst, let’s load the dataset from a CSV file and convert to a GeoDataFrame:\n\n\nCode\n# Load the data from a CSV file into a pandas DataFrame\ntrash_requests_df = pd.read_csv(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/trash_311_requests_2020.csv\"\n)\n\n# Remove rows with missing geometry\ntrash_requests_df = trash_requests_df.dropna(subset=[\"lat\", \"lon\"])\n\n\n# Create our GeoDataFrame with geometry column created from lon/lat\ntrash_requests = gpd.GeoDataFrame(\n    trash_requests_df,\n    geometry=gpd.points_from_xy(trash_requests_df[\"lon\"], trash_requests_df[\"lat\"]),\n    crs=\"EPSG:4326\",\n)\n\n\nLoad neighborhoods and do the spatial join to associate a neighborhood with each ticket:\n\n\nCode\n# Load the neighborhoods\nneighborhoods = gpd.read_file(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/zillow_neighborhoods.geojson\"\n)\n\n# Do the spatial join to add the \"ZillowName\" column\nrequests_with_hood = gpd.sjoin(\n    trash_requests,\n    neighborhoods.to_crs(trash_requests.crs),\n    predicate=\"within\",\n)\n\n\nLet’s explore the 311 requests in the Greenwich neighborhood of the city:\n\n# Extract out the point tickets for Greenwich\ngreenwich_tickets = requests_with_hood.query(\"ZillowName == 'Greenwich'\")\n\n\n# Get the neighborhood boundary for Greenwich\ngreenwich_geo = neighborhoods.query(\"ZillowName == 'Greenwich'\")\n\ngreenwich_geo.squeeze().geometry\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuarto has callout blocks that you can use to emphasize content in different ways. This is a “Note” callout block. More info is available on the Quarto documentation.\n\n\nImport the packages we need:\n\nimport folium\nimport xyzservices\n\nCombine the tickets as markers and the neighborhood boundary on the same Folium map:\n\n# Plot the neighborhood boundary\nm = greenwich_geo.explore(\n    style_kwds={\"weight\": 4, \"color\": \"black\", \"fillColor\": \"none\"},\n    name=\"Neighborhood boundary\",\n    tiles=xyzservices.providers.CartoDB.Voyager,\n)\n\n\n# Add the individual tickets as circle markers and style them\ngreenwich_tickets.explore(\n    m=m,  # Add to the existing map!\n    marker_kwds={\"radius\": 7, \"fill\": True, \"color\": \"crimson\"},\n    marker_type=\"circle_marker\", # or 'marker' or 'circle'\n    name=\"Tickets\",\n)\n\n# Hse folium to add layer control\nfolium.LayerControl().add_to(m)\n\nm  # show map\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/1-python-code-blocks.html",
    "href": "analysis/1-python-code-blocks.html",
    "title": "Python code blocks",
    "section": "",
    "text": "This is an example from the Quarto documentation that shows how to mix executable Python code blocks into a markdown file in a “Quarto markdown” .qmd file.\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html",
    "href": "analysis/3-altair-hvplot.html",
    "title": "Altair and Hvplot Charts",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive charts produced using Altair and hvPlot."
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in Altair",
    "text": "Example: Measles Incidence in Altair\nFirst, let’s load the data for measles incidence in wide format:\n\n\nCode\nurl = \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/measles_incidence.csv\"\ndata = pd.read_csv(url, skiprows=2, na_values=\"-\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nWEEK\nALABAMA\nALASKA\nARIZONA\nARKANSAS\nCALIFORNIA\nCOLORADO\nCONNECTICUT\nDELAWARE\n...\nSOUTH DAKOTA\nTENNESSEE\nTEXAS\nUTAH\nVERMONT\nVIRGINIA\nWASHINGTON\nWEST VIRGINIA\nWISCONSIN\nWYOMING\n\n\n\n\n0\n1928\n1\n3.67\nNaN\n1.90\n4.11\n1.38\n8.38\n4.50\n8.58\n...\n5.69\n22.03\n1.18\n0.4\n0.28\nNaN\n14.83\n3.36\n1.54\n0.91\n\n\n1\n1928\n2\n6.25\nNaN\n6.40\n9.91\n1.80\n6.02\n9.00\n7.30\n...\n6.57\n16.96\n0.63\nNaN\n0.56\nNaN\n17.34\n4.19\n0.96\nNaN\n\n\n2\n1928\n3\n7.95\nNaN\n4.50\n11.15\n1.31\n2.86\n8.81\n15.88\n...\n2.04\n24.66\n0.62\n0.2\n1.12\nNaN\n15.67\n4.19\n4.79\n1.36\n\n\n3\n1928\n4\n12.58\nNaN\n1.90\n13.75\n1.87\n13.71\n10.40\n4.29\n...\n2.19\n18.86\n0.37\n0.2\n6.70\nNaN\n12.77\n4.66\n1.64\n3.64\n\n\n4\n1928\n5\n8.03\nNaN\n0.47\n20.79\n2.38\n5.13\n16.80\n5.58\n...\n3.94\n20.05\n1.57\n0.4\n6.70\nNaN\n18.83\n7.37\n2.91\n0.91\n\n\n\n\n5 rows × 53 columns\n\n\n\nThen, use the pandas.melt() function to convert it to tidy format:\n\n\nCode\nannual = data.drop(\"WEEK\", axis=1)\nmeasles = annual.groupby(\"YEAR\").sum().reset_index()\nmeasles = measles.melt(id_vars=\"YEAR\", var_name=\"state\", value_name=\"incidence\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nstate\nincidence\n\n\n\n\n0\n1928\nALABAMA\n334.99\n\n\n1\n1929\nALABAMA\n111.93\n\n\n2\n1930\nALABAMA\n157.00\n\n\n3\n1931\nALABAMA\n337.29\n\n\n4\n1932\nALABAMA\n10.21\n\n\n\n\n\n\n\nFinally, load altair:\n\nimport altair as alt\n\nAnd generate our final data viz:\n\n# use a custom color map\ncolormap = alt.Scale(\n    domain=[0, 100, 200, 300, 1000, 3000],\n    range=[\n        \"#F0F8FF\",\n        \"cornflowerblue\",\n        \"mediumseagreen\",\n        \"#FFEE00\",\n        \"darkorange\",\n        \"firebrick\",\n    ],\n    type=\"sqrt\",\n)\n\n# Vertical line for vaccination year\nthreshold = pd.DataFrame([{\"threshold\": 1963}])\n\n# plot YEAR vs state, colored by incidence\nchart = (\n    alt.Chart(measles)\n    .mark_rect()\n    .encode(\n        x=alt.X(\"YEAR:O\", axis=alt.Axis(title=None, ticks=False)),\n        y=alt.Y(\"state:N\", axis=alt.Axis(title=None, ticks=False)),\n        color=alt.Color(\"incidence:Q\", sort=\"ascending\", scale=colormap, legend=None),\n        tooltip=[\"state\", \"YEAR\", \"incidence\"],\n    )\n    .properties(width=650, height=500)\n)\n\nrule = alt.Chart(threshold).mark_rule(strokeWidth=4).encode(x=\"threshold:O\")\n\nout = chart + rule\nout"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in hvplot",
    "text": "Example: Measles Incidence in hvplot\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate the same data viz in hvplot:\n\n# Make the heatmap with hvplot\nheatmap = measles.hvplot.heatmap(\n    x=\"YEAR\",\n    y=\"state\",\n    C=\"incidence\", # color each square by the incidence\n    reduce_function=np.sum, # sum the incidence for each state/year\n    frame_height=450,\n    frame_width=600,\n    flip_yaxis=True,\n    rot=90,\n    colorbar=False,\n    cmap=\"viridis\",\n    xlabel=\"\",\n    ylabel=\"\",\n)\n\n# Some additional formatting using holoviews \n# For more info: http://holoviews.org/user_guide/Customizing_Plots.html\nheatmap = heatmap.redim(state=\"State\", YEAR=\"Year\")\nheatmap = heatmap.opts(fontsize={\"xticks\": 0, \"yticks\": 6}, toolbar=\"above\")\nheatmap"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "MUSA 550 Final Project",
    "section": "",
    "text": "Important\n\n\n\nKisumu is a port city in western Kenya at 1,131 m (3,711 ft) elevation. The port was founded in 1901 as the main inland terminal of the Uganda Railway and named Port Florence.\nI am using scikit-learn for k-means clustering to classify Landsat 8 imagery for understanding urban landscapes in Kisumu. Then, I applied OSMnx for street network analysis in Kisumu to evaluate urban walkability, focusing on factors like street density and accessibility to amenities. This approach allowed me to assess the relationship between urban form and walkability in Kisumu.\nPotential Data Sources:\n\nESRIWorldImageryWaybackSatelliteData\nGoogleEarthEngine\nOSMStreetMapsData"
  },
  {
    "objectID": "analysis/2-static-images.html",
    "href": "analysis/2-static-images.html",
    "title": "Showing static visualizations",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and demonstrates how to generate static visualizations with matplotlib, pandas, and seaborn.\nStart by importing the packages we need:\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nLoad the “Palmer penguins” dataset from week 2:\n# Load data on Palmer penguins\npenguins = pd.read_csv(\"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/penguins.csv\")\n# Show the first ten rows\npenguins.head(n=10)    \n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195.0\n4675.0\nmale\n2007\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n2007\n\n\n9\nAdelie\nTorgersen\n42.0\n20.2\n190.0\n4250.0\nNaN\n2007"
  },
  {
    "objectID": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "href": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "title": "Showing static visualizations",
    "section": "A simple visualization, 3 different ways",
    "text": "A simple visualization, 3 different ways\n\nI want to scatter flipper length vs. bill length, colored by the penguin species\n\n\nUsing matplotlib\n\n# Setup a dict to hold colors for each species\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Initialize the figure \"fig\" and axes \"ax\"\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Group the data frame by species and loop over each group\n# NOTE: \"group\" will be the dataframe holding the data for \"species\"\nfor species, group_df in penguins.groupby(\"species\"):\n\n    # Plot flipper length vs bill length for this group\n    # Note: we are adding this plot to the existing \"ax\" object\n    ax.scatter(\n        group_df[\"flipper_length_mm\"],\n        group_df[\"bill_length_mm\"],\n        marker=\"o\",\n        label=species,\n        color=color_map[species],\n        alpha=0.75,\n        zorder=10\n    )\n\n# Plotting is done...format the axes!\n\n## Add a legend to the axes\nax.legend(loc=\"best\")\n\n## Add x-axis and y-axis labels\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\n\n## Add the grid of lines\nax.grid(True);\n\n\n\n\n\n\nHow about in pandas?\nDataFrames have a built-in “plot” function that can make all of the basic type of matplotlib plots!\nFirst, we need to add a new “color” column specifying the color to use for each species type.\nUse the pd.replace() function: it use a dict to replace values in a DataFrame column.\n\n# Calculate a list of colors\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Map species name to color \npenguins[\"color\"] = penguins[\"species\"].replace(color_map)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\ncolor\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n#1f77b4\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n#1f77b4\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n#1f77b4\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n#1f77b4\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n#1f77b4\n\n\n\n\n\n\n\nNow plot!\n\n# Same as before: Start by initializing the figure and axes\nfig, myAxes = plt.subplots(figsize=(10, 6))\n\n# Scatter plot two columns, colored by third\n# Use the built-in pandas plot.scatter function\npenguins.plot.scatter(\n    x=\"flipper_length_mm\",\n    y=\"bill_length_mm\",\n    c=\"color\",\n    alpha=0.75,\n    ax=myAxes, # IMPORTANT: Make sure to plot on the axes object we created already!\n    zorder=10\n)\n\n# Format the axes finally\nmyAxes.set_xlabel(\"Flipper Length (mm)\")\nmyAxes.set_ylabel(\"Bill Length (mm)\")\nmyAxes.grid(True);\n\n\n\n\nNote: no easy way to get legend added to the plot in this case…\n\n\nSeaborn: statistical data visualization\nSeaborn is designed to plot two columns colored by a third column…\n\n# Initialize the figure and axes\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# style keywords as dict\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\nstyle = dict(palette=color_map, s=60, edgecolor=\"none\", alpha=0.75, zorder=10)\n\n# use the scatterplot() function\nsns.scatterplot(\n    x=\"flipper_length_mm\",  # the x column\n    y=\"bill_length_mm\",  # the y column\n    hue=\"species\",  # the third dimension (color)\n    data=penguins,  # pass in the data\n    ax=ax,  # plot on the axes object we made\n    **style  # add our style keywords\n)\n\n# Format with matplotlib commands\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\nax.grid(True)\nax.legend(loc=\"best\");"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MUSA 550 Final Project Template",
    "section": "",
    "text": "We can create beautiful websites that describe complex technical analyses in Python using Quarto and deploy them online using GitHub Pages. This combination of tools is a really powerful way to create and share your work. This website is a demo that is meant to be used to create your own Quarto website for the final project in MUSA 550.\nQuarto is a relatively new tool, but is becoming popular quickly. It’s a successor to the Rmarkdown ecosystem that combines functionality into a single tool and also extends its computation power to other languages. Most importantly for us, Quarto supports executing Python code, allowing us to convert Jupyter notebooks to HTML and share them online.\n\n\n\n\n\n\nImportant\n\n\n\nThis template site, including the layout it uses, is just a suggested place to start! For your final project, you’re welcome (and encouraged) to make as many changes as you like to best fit your project."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "MUSA 550 Final Project Template",
    "section": "",
    "text": "We can create beautiful websites that describe complex technical analyses in Python using Quarto and deploy them online using GitHub Pages. This combination of tools is a really powerful way to create and share your work. This website is a demo that is meant to be used to create your own Quarto website for the final project in MUSA 550.\nQuarto is a relatively new tool, but is becoming popular quickly. It’s a successor to the Rmarkdown ecosystem that combines functionality into a single tool and also extends its computation power to other languages. Most importantly for us, Quarto supports executing Python code, allowing us to convert Jupyter notebooks to HTML and share them online.\n\n\n\n\n\n\nImportant\n\n\n\nThis template site, including the layout it uses, is just a suggested place to start! For your final project, you’re welcome (and encouraged) to make as many changes as you like to best fit your project."
  },
  {
    "objectID": "index.html#find-out-more",
    "href": "index.html#find-out-more",
    "title": "MUSA 550 Final Project Template",
    "section": "Find out more",
    "text": "Find out more\nThe code for this repository is hosted on our course’s GitHub page: https://github.com/MUSA-550-Fall-2023/quarto-website-template.\nWe covered the basics of getting started with Quarto and GitHub Pages in week 9. Take a look at the slides for lecture 9A to find out more."
  },
  {
    "objectID": "analysis/SatelliteImagery.html",
    "href": "analysis/SatelliteImagery.html",
    "title": "MUSA 550 Quarto",
    "section": "",
    "text": "# Final Project - Unsupervised Classification of Landsat 8 Imagery\n\nUnsupervised classification is valuable in satellite imagery for its efficiency in data compression and anomaly detection, such as cloud and ship identification. It’s also useful in semi-supervised learning, where it quickly categorizes unlabeled data, complementing partially labeled datasets.\nFor my analysis of satellite image classification, I first need to set up my coding environment. I’ll start by importing all the necessary libraries. These include numpy for handling arrays, rasterio for input/output operations with remotely sensed data, scikit-learn for unsupervised classification and model evaluation, and matplotlib for data visualization. I also use the os library to manage file paths.\nMy focus was on obtaining satellite imagery of Kisumu. For this, I used OSMnx to download the data and ensured the data was in the correct format and projection (CRS) for accurate analysis.\n\n\nCode\nimport os\nimport numpy as np\nimport rasterio as rio\nfrom rasterio.mask import mask\nfrom shapely.geometry import Point, mapping\nfrom shapely.geometry.polygon import Polygon\nfrom shapely.geometry import Point\nimport geopandas as gpd\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler\nfrom skimage.exposure import equalize_adapthist\nimport matplotlib.pyplot as plt\n\n\n\n\nCode\n#loading data\npath = 'data/landsat8'\ncomplete_dataset = os.listdir(path)\ncomplete_dataset = [path + x for x in complete_dataset]\nprint(complete_dataset)\n\n\n['data/landsat8.DS_Store', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B9.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B8.tif', 'data/landsat8Icon\\r', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B10.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B11.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B6.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B7.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B5.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B4.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B1.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B3.tif', 'data/landsat8LC08_L1TP_170060_20230210_20230217_02_T1_B2.tif']\n\n\n\n\nCode\npath = 'data/landsat8'  \nbands_list = [os.path.join(path, filename) for filename in os.listdir(path) if filename.endswith('.tif')]  \n\n\nBefore diving into the analysis, I started by visualizing the scene to understand its characteristics. For this, I use bands 2, 3, and 4 of the Landsat 8 scene. When applying the k-means algorithm, I incorporate a broader range of data, including bands 1 to 11. Since all these bands have a resolution of 30 meters per pixel, there’s no need for upsampling or downsampling in the analysis.\n\n\nCode\ndef show_rgb(bands_list, red=4, green=3, blue=2):\n    stack = []\n    for band_number in [red, green, blue]:\n        # Adjust the pattern to match the filename structure we see in the output\n        band_file = next((band for band in bands_list if f\"T1_B{band_number}.tif\" in band), None)\n        if band_file:\n            with rio.open(band_file) as src:\n                array = src.read(1)\n                # Normalize the array\n                array = array.astype('float32')\n                array_min, array_max = array.min(), array.max()\n                array = (array - array_min) / (array_max - array_min)\n                stack.append(array)\n        else:\n            print(f\"No band file found for band number {band_number}\")\n\n    if stack:  # Check if stack is not empty\n        stack = np.dstack(stack)\n        # Display the image\n        plt.figure(figsize=(15, 15))\n        plt.axis('off')\n        plt.imshow(stack)\n        plt.show()\n    else:\n        print(\"No arrays were added to stack, check the band files.\")\n\n\n\n\nCode\n# Example of using bands_list\nband_number = 4  # Replace with the correct band number you are looking for\nband_file = next((band for band in bands_list if f\"T1_B{band_number}.tif\" in band), None)\n\n\n\n\nCode\nband_file = next((band for band in bands_list if f\"T1_B{band_number}.tif\" in band), None)\n\n\n\n\n['data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B9.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B8.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B10.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B11.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B6.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B7.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B5.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B4.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B1.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B3.tif', 'data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B2.tif']\n\n\n\n\n\nThe Kisumu area was densely packed with buildings and structures, making it challenging to discern vegetation or subtle details in the predominantly brownish images. To enhance visualization, particularly of man-made objects, I utilized a different band combination: 7-6-4. This selection significantly emphasizes these features. I adjusted the red, green, and blue arguments in the show_rgb function to accommodate this new combination.\n\n\n\n\n\n\n\nCode\nshow_rgb(bands_list, red=5, green=4, blue=3)\n\n\n\n\n\nFor the models development, I employed the KMeans package to classify pixel values in the satellite images. I experimented with different numbers of clusters to understand which best captures the terrain types in the scene. To determine the number of clusters that best represent the terrain types, I experimented with 3 and 6 clusters, stacking all bands for a comprehensive analysis.\n\n\nCode\n# Stack all bands\ndef stack_bands(bands_list):\n    stack = []\n    for band_path in bands_list:\n        with rio.open(band_path) as src:\n            stack.append(src.read(1).flatten())  # Flatten each band\n    return np.stack(stack, axis=1)\n\n\n\n\nCode\nfor band_path in bands_list:\n    with rio.open(band_path) as src:\n        array = src.read(1)\n        print(array.shape)  # Print out the shape of each array\n\n\n(279, 280)\n(558, 558)\n(279, 280)\n(279, 280)\n(279, 280)\n(279, 280)\n(279, 280)\n(279, 280)\n(279, 280)\n(279, 280)\n(279, 280)\n\n\n\n\nCode\ndef stack_bands(bands_list):\n    stack = []\n    for band_path in bands_list:\n        with rio.open(band_path) as src:\n            array = src.read(1)\n            # Only append bands that match the desired shape (279, 280) for example\n            if array.shape == (279, 280):\n                stack.append(array.flatten())  # Flatten each band\n            else:\n                print(f\"Excluded {band_path} due to shape mismatch: {array.shape}\")\n    return np.vstack(stack).T  # Use vstack and transpose to get the correct shape for KMeans\n\n# Get the stacked data excluding any mismatched bands\ndata_stack = stack_bands(bands_list)\n\n\nExcluded data/landsat8/LC08_L1TP_170060_20230210_20230217_02_T1_B8.tif due to shape mismatch: (558, 558)\n\n\n\n\nCode\n# Stack all bands\ndef stack_bands(bands_list):\n    stack = []\n    for band_path in bands_list:\n        with rio.open(band_path) as src:\n            stack.append(src.read(1).flatten())  # Flatten each band\n    return np.stack(stack, axis=1)\n\n\n\n\nCode\n# Reshape the data\ndata_stack = stack_bands(bands_list)\n\n\nValueError: all input arrays must have the same shape\n\n\n\n\nCode\n# Standardize the data\nscaler = StandardScaler()\ndata_standardized = scaler.fit_transform(data_stack)\n\n\n\n\nCode\n# Determine the optimal number of clusters\n# Use methods like the Elbow method or Silhouette score here\n\n# Sample for silhouette score\nrange_n_clusters = [2, 3, 4, 5, 6]\nsilhouette_avg = []\nfor num_clusters in range_n_clusters:\n    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n    cluster_labels = kmeans.fit_predict(data_standardized)\n    silhouette_avg.append(silhouette_score(data_standardized, cluster_labels))\n\n\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n\nCode\n# Choose the optimal number of clusters\noptimal_clusters = range_n_clusters[silhouette_avg.index(max(silhouette_avg))]\n\n\n\n\nCode\n# Apply K-Means Clustering\nkmeans6 = KMeans(n_clusters=6, random_state=42)\ny_pred = kmeans.fit_predict(data_standardized)\n\n\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n\nCode\n# Reshape classified data back to the original image shape\nwith rio.open(bands_list[0]) as src:\n    meta = src.meta\n    original_shape = (src.height, src.width)\nclassified_image6 = y_pred.reshape(original_shape)\n\n\n\n\n\n\n\n\n\nCluster 0: 29.80%\nCluster 1: 14.53%\nCluster 2: 4.30%\nCluster 3: 11.55%\nCluster 4: 28.88%\nCluster 5: 10.93%\n\n\n\n\nCode\n# Apply K-Means Clustering\nkmeans3 = KMeans(n_clusters=3, random_state=42)\ny_pred = kmeans3.fit_predict(data_standardized)\n\n# Reshape classified data back to the original image shape\nwith rio.open(bands_list[0]) as src:\n    meta = src.meta\n    original_shape = (src.height, src.width)\nclassified_image3 = y_pred.reshape(original_shape)\n\n# Visualize the result\nplt.figure(figsize=(10, 10))\nplt.imshow(classified_image3, cmap='terrain')\nplt.colorbar()\nplt.show()\n\n\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)\n\n\n\n\n\n\n\nCluster 0: 42.46%\nCluster 1: 15.46%\nCluster 2: 42.09%\n\n\n\nclustered_models = ClusteredBands(complete_dataset)\nclustered_models.set_raster_stack()\n\nAfter comparing the resulting images with the original RGB scene, I conclude that six categories yield the most optimal results. Three categories fail to capture the spatial variability, with a significant presence of NaN values obscuring useful data."
  },
  {
    "objectID": "analysis/Walkability.html",
    "href": "analysis/Walkability.html",
    "title": "MUSA 550 Quarto",
    "section": "",
    "text": "# Final Project - Analysing Urban Walkability\n\nIntersection density reflects the compactness and connectivity of a street network, key indicators of walkability. A dense network minimizes unreachable areas, while high connectivity allows for multiple routing options.\nInitially, the walkable network of the study area was downloaded using OSMnx, forming a graph of edges (paths) and nodes (intersections).\n\n\nCode\nimport osmnx as ox\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport seaborn as sns\nimport os\nimport numpy as np\nimport rasterio as rio\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom skimage.exposure import equalize_adapthist\nimport matplotlib.pyplot as plt\nimport pandana\n\n%matplotlib inline\n\n\n\n\nCode\n# Select city and crs\ncityname = 'kisumu, kenya'\ncrs = 32636\n\n\n\n\nCode\n# Get graph by geocoding\ngraph = ox.graph_from_place(cityname, network_type=\"walk\")\n\n# Project graph\ngraph = ox.projection.project_graph(graph, to_crs=crs)\n\n\n\n\nCode\n# Simplify to get real intersections only\n# (consolidate nodes within a distance from eachother)\ngraph_simplified = ox.simplification.consolidate_intersections(\n    # Graph to simplify\n    graph,\n    # buffer around each node (project the graph beforehand)\n    tolerance=5,\n    # Get result as graph (False to get nodes only as gdf)\n    rebuild_graph=True,\n    # no dead ends\n    dead_ends=False,\n    # Reconnect (False to get intersections only)\n    reconnect_edges=True\n)\n\n\n\n\nCode\n# everything to gdfs\nnodes, edges = ox.graph_to_gdfs(graph)\nnodes_s, edges_s = ox.graph_to_gdfs(graph_simplified)\n\n\n\n\n\n\n\nTo address overcomplexity, like minor discrepancies creating multiple nodes for a single intersection, the graph was simplified. Nodes within five meters were merged, and cul-de-sacs were removed, yielding a representation that more accurately reflects true intersections.\n\n\n\n\n\n\n\nCode\n# Print info\nprint(\n    'number of nodes:\\n\\noriginal graph: '+str(len(nodes))\n    +'\\nsimplified graph: '+str(len(nodes_s))\n)\n\n\nnumber of nodes:\n\noriginal graph: 5319\nsimplified graph: 6153\n\n\nThe simplified reduced intersections and their mere agglomeration of nodes does little to convey meaningful information. To illustrate spatial variations in density, I employed Matplotlib’s hexbin function and explored Seaborn’s KDE plots for a more nuanced depiction.\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save nodes\nnodes.to_file('./data/nodes.gpkg', driver='GPKG')\nnodes_s.to_file('./data/nodes_simplified.gpkg', driver='GPKG')\n\n\nThe initial analysis equated dense urban fabric with walkability, but urban space encompasses more than just intersections. For my analysis I used the list of OSM features that indicate sociable places, or so called “third places“. With OSMnx and Pandana, a detailed network was created, positioning the POIs. Here, I used the intricate, original graph for accurate travel time computations. Pandana’s routing analysis calculated walking times from each node to ten proximal POIs, assuming a walking speed of 4.5 km/h and capping at a 15-minute walking radius.\n\n\nCode\n# Select city and crs\ncityname = 'kisumu, kenya'\ncrs = 32636\n\n\n\n\nCode\n# Get graph by geocoding\ngraph = ox.graph_from_place(cityname, network_type=\"walk\")\n\n# Project graph\ngraph = ox.projection.project_graph(graph, to_crs=crs)\n\n\n\n\nCode\n# Select points of interest based on osm tags\ntags = {\n    'amenity':[\n        'cafe',\n        'bar',\n        'pub',\n        'restaurant'\n    ],\n    'shop':[\n        'bakery',\n        'convenience',\n        'supermarket',\n        'mall',\n        'department_store',\n        'clothes',\n        'fashion',\n        'shoes'\n    ],\n    'leisure':[\n        'fitness_centre'\n    ]\n}\n\n# Get amentities from place\npois = ox.geometries.geometries_from_place(cityname, tags=tags)\n    \n# Project pois\npois = pois.to_crs(epsg=crs)\n\n\n/var/folders/b2/qx41_qqs0ssddj67gfv4v4kr0000gn/T/ipykernel_24350/615437948.py:27: UserWarning: The `geometries` module and `geometries_from_X` functions have been renamed the `features` module and `features_from_X` functions. Use these instead. The `geometries` module and function names are deprecated and will be removed in a future release.\n  pois = ox.geometries.geometries_from_place(cityname, tags=tags)\n\n\n\n\nCode\n# Max time to walk in minutes (no routing to nodes further than this)\nwalk_time = 15\n\n# Walking speed\nwalk_speed = 4.5\n\n# Set a uniform walking speed on every edge\nfor u, v, data in graph.edges(data=True):\n    data['speed_kph'] = walk_speed\ngraph = ox.add_edge_travel_times(graph)\n\n# Extract node/edge GeoDataFrames, retaining only necessary columns (for pandana)\nnodes = ox.graph_to_gdfs(graph, edges=False)[['x', 'y']]\nedges = ox.graph_to_gdfs(graph, nodes=False).reset_index()[['u', 'v', 'travel_time']]\n\n\n\n\nCode\n# Construct the pandana network model\nnetwork = pandana.Network(\n    node_x=nodes['x'],\n    node_y=nodes['y'], \n    edge_from=edges['u'],\n    edge_to=edges['v'],\n    edge_weights=edges[['travel_time']]\n)\n\n# Extract centroids from the pois' geometries\ncentroids = pois.centroid\n\n\nGenerating contraction hierarchies with 8 threads.\nSetting CH node vector of size 9278\nSetting CH edge vector of size 23422\nRange graph removed 23576 edges of 46844\n. 10% . 20% . 30% . 40% . 50% . 60% . 70% . 80% . 90% . 100%\n\n\n\n\nCode\n# Specify a max travel distance for analysis\n# Minutes -&gt; seconds\nmaxdist = walk_time * 60\n\n# Set the pois' locations on the network\nnetwork.set_pois(\n    category='pois',\n    maxdist=maxdist,\n    maxitems=10,\n    x_col=centroids.x, \n    y_col=centroids.y\n)\n\n\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/pandana/network.py:753: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n  elif isinstance(maxitems, type(pd.Series())):\n/Users/kamya14o2/mambaforge/envs/musa-550-fall-2023/lib/python3.10/site-packages/pandana/network.py:761: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n  elif isinstance(maxdist, type(pd.Series())):\n\n\n\n\nCode\n# calculate travel time to 10 nearest pois from each node in network\ndistances = network.nearest_pois(\n    distance=maxdist,\n    category='pois',\n    num_pois=10\n)\n\ndistances.astype(int).head()\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nosmid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n394066125\n627\n783\n900\n900\n900\n900\n900\n900\n900\n900\n\n\n10230373047\n634\n789\n900\n900\n900\n900\n900\n900\n900\n900\n\n\n6335457201\n586\n741\n900\n900\n900\n900\n900\n900\n900\n900\n\n\n6166827034\n250\n406\n900\n900\n900\n900\n900\n900\n900\n900\n\n\n394072307\n220\n389\n632\n635\n707\n900\n900\n900\n900\n900\n\n\n\n\n\n\n\n\n\n\n\n\nThe initial visualization was dense; clarity was improved using Matplotlib’s hexbins, this time mapping average walking times per hex. Notably, showing only the nearest POI can be misleading—a tight cluster of amenities could visually equate to an area with a single amenity. Adjusting the metric to, say, the 5th or 10th nearest POI, can provide a more balanced view, as seen in the comparative visualizations.\n\n\n/var/folders/b2/qx41_qqs0ssddj67gfv4v4kr0000gn/T/ipykernel_24350/1260560219.py:73: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  plt.tight_layout()\n\n\n\n\n\n\n\nCode\n# check data\ndistances.head()\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nosmid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n394066125\n627.900024\n783.099976\n900.000000\n900.000000\n900.000000\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n10230373047\n634.200012\n789.400024\n900.000000\n900.000000\n900.000000\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n6335457201\n586.200012\n741.400024\n900.000000\n900.000000\n900.000000\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n6166827034\n250.899994\n406.100006\n900.000000\n900.000000\n900.000000\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n394072307\n220.399994\n389.299988\n632.200012\n635.900024\n707.900024\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n\n\n\n\n\n\n\nCode\nnodes.head()\n\n\n\n\n\n\n\n\n\nx\ny\n\n\nosmid\n\n\n\n\n\n\n394066125\n698732.530899\n-12599.765594\n\n\n10230373047\n698727.899994\n-12593.495188\n\n\n6335457201\n698755.517259\n-12649.905862\n\n\n6166827034\n699003.214915\n-12983.410248\n\n\n394072307\n695563.344670\n-9783.976847\n\n\n\n\n\n\n\n\n\nCode\n# Get nodes with wgs coords for output csv\ngraph_wgs = ox.projection.project_graph(graph, to_crs=32636)\nnodes_wgs = ox.graph_to_gdfs(graph_wgs, edges=False)[['x', 'y']]\n\n\n\n\nCode\n# Join travel time info to nodes\nwalk_access = nodes.join(distances, on='osmid', how='left')\nwalk_access_wgs = nodes_wgs.join(distances, on='osmid', how='left')\n\n\n\n\nCode\nwalk_access_wgs.head()\n\n\n\n\n\n\n\n\n\nx\ny\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nosmid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n394066125\n698732.530899\n-12599.765594\n627.900024\n783.099976\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n10230373047\n698727.899994\n-12593.495188\n634.200012\n789.400024\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n6335457201\n698755.517259\n-12649.905862\n586.200012\n741.400024\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n6166827034\n699003.214915\n-12983.410248\n250.899994\n406.100006\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n6335457193\n698431.273645\n-12430.697247\n900.000000\n900.000000\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n900.0\n\n\n\n\n\n\n\n\n\nCode\n# Save as CSV\nwalk_access_wgs.to_csv('./data/walk_access.csv', encoding='utf-8')"
  },
  {
    "objectID": "analysis/Conclusion.html",
    "href": "analysis/Conclusion.html",
    "title": "MUSA 550 Quarto",
    "section": "",
    "text": "Conclusions:\nInitial visual assessment of the walkability map and the unsupervised classification map suggests a potential relationship between urban land use clusters and areas with higher walkability scores in Kisumu. Urban clusters, as identified by the classification algorithm, appear to correspond with regions that have shorter walking times to points of interest, which may indicate better walkability. Conversely, less walkable areas might align with land use clusters that are characteristic of rural or undeveloped regions. To confirm and quantify this relationship, a comprehensive spatial analysis is recommended.\n\nimport geopandas as gpd\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.stats import pearsonr\n\nfrom IPython.display import Image, display\n\nimport rasterio\nimport numpy as np\nfrom shapely.geometry import Point"
  },
  {
    "objectID": "analysis/index.html#welcome",
    "href": "analysis/index.html#welcome",
    "title": "MUSA 550 Final Project",
    "section": "",
    "text": "Important\n\n\n\nKisumu is a port city in western Kenya at 1,131 m (3,711 ft) elevation. The port was founded in 1901 as the main inland terminal of the Uganda Railway and named Port Florence.\nI am using scikit-learn for k-means clustering to classify Landsat 8 imagery for understanding urban landscapes in Kisumu. Then, I applied OSMnx for street network analysis in Kisumu to evaluate urban walkability, focusing on factors like street density and accessibility to amenities. This approach allowed me to assess the relationship between urban form and walkability in Kisumu.\nPotential Data Sources:\n\nESRIWorldImageryWaybackSatelliteData\nGoogleEarthEngine\nOSMStreetMapsData"
  },
  {
    "objectID": "analysis/index.html#find-out-more",
    "href": "analysis/index.html#find-out-more",
    "title": "MUSA 550 Final Project",
    "section": "Find out more",
    "text": "Find out more\nThe code for this repository is hosted on our course’s GitHub page: https://github.com/MUSA-550-Fall-2023/quarto-website-template.\nWe covered the basics of getting started with Quarto and GitHub Pages in week 9. Take a look at the slides for lecture 9A to find out more."
  },
  {
    "objectID": "analysis/about.html",
    "href": "analysis/about.html",
    "title": "About me",
    "section": "",
    "text": "My name is Kamya Khandelwal and I am a City Planning student with Urban Design focus from the University of Pennsylvania, and three years experience in urban development and community engagement. I am looking forward to applying design and planning skills for transformative projects.\nThis site is an example site showing how to use Quarto for the final project for MUSA 550, during fall 2023."
  }
]